#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Mon Nov 28 12:32:08 2022

@author: simon
"""

input_processor_name: default

output_size: [10240, 5632]
output_region: [-16.0,48.0,10.666666666666666,62.666666666666664]

output_writer_name: zarr

output_writer_params: 
  chunksizes: 
    lat: 704
    lon: 640
    
output_resampling: Nearest

output_variables:
  - analysed_sst


# xcube global dataset metadata
#
# * NetCDF Attribute Convention for Dataset Discovery (as used by THREDDS data server catalogue)
#   https://www.unidata.ucar.edu/software/thredds/current/netcdf-java/metadata/DataDiscoveryAttConvention.html
# * CF Conventions
#   http://cfconventions.org/Data/cf-conventions/cf-conventions-1.7/cf-conventions.html#description-of-file-contents
#
output_metadata:
  # CF: A succinct description of what is in the dataset.
  title: "CMEMS Global SST Anomaly Data Cube"

  # CF: The method of production of the original data.
  # If it was model-generated, source should name the model and its version, as specifically as could be useful.
  # If it is observational, source should characterize it (e.g., "surface observation" or "radiosonde").
  source: "CMEMS Global SST & Sea Ice Anomaly Data Cube"


  # CF: Published or web-based references that describe the data or methods used to produce it.
  references: "https://dcs4cop.eu/"

  # CF: Miscellaneous information about the data or methods used to produce it.
  comment: ""

  # A paragraph describing the dataset.
  summary: ""

  # A comma separated list of key words and phrases.
  keywords: ""

  # The combination of the "naming authority" and the "id" should be a globally unique identifier for the dataset.
  id: "demo-bc-sst-sns-l2c-v1"
  naming_authority: "bc"

  # The scientific project that produced the data.
  project: "xcube"

  # A textual description of the processing (or quality control) level of the data.
  processing_level: "L2C"

  # A place to acknowledge various type of support for the project that produced this data.
  acknowledgment: "Data Cube produced based on data provided by GHRSST, Met Office and CMEMS"

  # The name of the controlled vocabulary from which variable standard names are taken.
  standard_name_vocabulary: ""

  # Describe the restrictions to data access and distribution.
  license: "terms and conditions of the DCS4COP data distribution"

  # CF: Provides an audit trail for modifications to the original data.
  # Well-behaved generic netCDF filters will automatically append their name and the
  # parameters with which they were invoked to the global history attribute of an input netCDF file.
  # We recommend that each line begin with a timestamp indicating the date and time of day
  # that the program was executed.
  history: "xcube/reproj-snap-nc"

  # CF: Specifies where the original data was produced.
  institution: "Brockmann Consult GmbH"

  # The data creator's name, URL, and email.
  # The "institution" attribute will be used if the "creator_name" attribute does not exist.
  creator:
    - name: "Brockmann Consult GmbH"
      url: "https://www.brockmann-consult.de"
      email: "info@brockmann-consult.de"

  publisher:
    - name:  "Brockmann Consult GmbH"
      url:   "https://www.brockmann-consult.de"
      email: "info@brockmann-consult.de"

  # The name and role of any individuals or institutions that contributed to the creation of this data.
  contributor:
    - name: ""
      role: ""

  #  date:
  #    # The date on which the data was created.
  #    created:  2018-05-30
  #    # The date on which this data was last modified.
  #    modified: 2018-05-30
  #    # The date on which this data was formally issued.
  #    issued:   2018-06-01

  # Describes a simple latitude, longitude, and vertical bounding box units and resolution attributes.

  #  geospatial_lon:
  #    min:  -16.0
  #    max:  10.666666666666666
  #    units: "degrees_east"
  #    resolution: 0.002604167
  #
  #  geospatial_lat:
  #    min: 48.0
  #    max: 62.666666666666664
  #    units: "degrees_north"
  #    resolution: 0.002604167

  # Describes the temporal coverage of the data as a time range.
  # Only provide it here, if you don't want it to be computed.

  #  time_coverage:
  #    start:      2017-01-01
  #    end:        2017-12-31
  #    duration:   "P1Y"
  #    resolution: "1D"